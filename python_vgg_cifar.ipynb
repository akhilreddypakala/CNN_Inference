{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "python_vgg_cifar.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9b3NRrEQqZc2jtb2SfVpx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilreddypakala/CNN_Inference/blob/master/python_vgg_cifar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEjSi5vTfkh2",
        "outputId": "ac4add40-baef-4d45-f42f-31f0cf321e68"
      },
      "source": [
        "!git clone https://github.com/chengyangfu/pytorch-vgg-cifar10.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-vgg-cifar10'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Total 67 (delta 0), reused 0 (delta 0), pack-reused 67\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm21JpoHgn7A",
        "outputId": "69a5ed44-9275-4c05-e3d3-a00c41ea9e6b"
      },
      "source": [
        "!wget http://www.cs.unc.edu/~cyfu/cifar10/model_best.pth.tar\n",
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 04:57:38--  http://www.cs.unc.edu/~cyfu/cifar10/model_best.pth.tar\n",
            "Resolving www.cs.unc.edu (www.cs.unc.edu)... 152.2.142.1\n",
            "Connecting to www.cs.unc.edu (www.cs.unc.edu)|152.2.142.1|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82223980 (78M) [application/x-tar]\n",
            "Saving to: ‘model_best.pth.tar’\n",
            "\n",
            "model_best.pth.tar  100%[===================>]  78.41M  36.2MB/s    in 2.2s    \n",
            "\n",
            "2020-12-20 04:57:41 (36.2 MB/s) - ‘model_best.pth.tar’ saved [82223980/82223980]\n",
            "\n",
            "python3: can't open file 'main.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8xEeCYlFgp-z",
        "outputId": "ea79d3e3-84eb-4ae9-d3d2-d917b24950d9"
      },
      "source": [
        "pwd\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8UwBsBvgu3q",
        "outputId": "a4321ceb-39cd-4970-c5bc-13e09a3b4399"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_best.pth.tar  pytorch-vgg-cifar10  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TjT8g9ygwg7",
        "outputId": "3c6242f2-97f2-4c87-efb9-329115e280c0"
      },
      "source": [
        "cd pytorch-vgg-cifar10/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch-vgg-cifar10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsJyjMS8g1p9",
        "outputId": "37e5e859-0fc9-49f7-814f-97c527b66b78"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'main.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7lBhxHQg5Wb",
        "outputId": "2f00a809-e903-40d1-dc97-320ead94862a"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvZv5bC6hKrO",
        "outputId": "c0395230-8f0b-4315-dcc6-b25f75cfaed3"
      },
      "source": [
        "cd ../\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1uEmw6lhMcY",
        "outputId": "437c817f-35a2-45a2-a067-4e11c1c608f5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   swift\t       tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t       tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-1.15.2  usr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiFxVemwhSJ7",
        "outputId": "473454cf-2875-4a8e-9d9b-2763670c9841"
      },
      "source": [
        "cd content/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MiH0_d6hURb",
        "outputId": "3671b71a-64f7-4e80-fa27-fc57c6661617"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRSm08-2hWMR",
        "outputId": "d01bcb6d-9e4a-4de5-dd1a-648fb93e64c3"
      },
      "source": [
        "!git clone https://github.com/chengyangfu/pytorch-vgg-cifar10.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-vgg-cifar10'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Total 67 (delta 0), reused 0 (delta 0), pack-reused 67\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNcAvqP3hZPk",
        "outputId": "eb36d8e6-8be5-43d4-8a49-7c6defbb01ab"
      },
      "source": [
        "cd pytorch-vgg-cifar10/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch-vgg-cifar10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG5lGH2KhckY",
        "outputId": "c114eeb4-567e-4555-91fb-cb2418adc363"
      },
      "source": [
        "!wget http://www.cs.unc.edu/~cyfu/cifar10/model_best.pth.tar\n",
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 05:01:21--  http://www.cs.unc.edu/~cyfu/cifar10/model_best.pth.tar\n",
            "Resolving www.cs.unc.edu (www.cs.unc.edu)... 152.2.142.1\n",
            "Connecting to www.cs.unc.edu (www.cs.unc.edu)|152.2.142.1|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82223980 (78M) [application/x-tar]\n",
            "Saving to: ‘model_best.pth.tar’\n",
            "\n",
            "model_best.pth.tar  100%[===================>]  78.41M  34.0MB/s    in 2.3s    \n",
            "\n",
            "2020-12-20 05:01:23 (34.0 MB/s) - ‘model_best.pth.tar’ saved [82223980/82223980]\n",
            "\n",
            "=> loading checkpoint './model_best.pth.tar'\n",
            "=> loaded checkpoint 'True' (epoch 233)\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "170500096it [00:03, 43554737.05it/s]                   \n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "main.py:220: UserWarning: This overload of cuda is deprecated:\n",
            "\tcuda(torch.device device, bool async, *, torch.memory_format memory_format)\n",
            "Consider using one of the following signatures instead:\n",
            "\tcuda(torch.device device, bool non_blocking, *, torch.memory_format memory_format) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  input = input.cuda(async=True)\n",
            "Test: [0/79]\tTime 0.874 (0.874)\tLoss 0.2798 (0.2798)\tPrec@1 95.312 (95.312)\n",
            "Test: [20/79]\tTime 0.028 (0.066)\tLoss 0.4300 (0.4210)\tPrec@1 91.406 (92.448)\n",
            "Test: [40/79]\tTime 0.020 (0.047)\tLoss 0.3954 (0.4370)\tPrec@1 92.188 (92.264)\n",
            "Test: [60/79]\tTime 0.033 (0.040)\tLoss 0.4454 (0.4327)\tPrec@1 92.969 (92.367)\n",
            " * Prec@1 92.430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saJLPo7uiADO",
        "outputId": "f6899b4a-e544-4e0f-d5c4-7094cb68ed0d"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7gQ0q2An0dP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f0b84e5-a021-4f81-cd6c-fc82a8ddd1c9"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98I9u80Poi4Y",
        "outputId": "8f0d7040-6160-466b-e12e-09d1411015a4"
      },
      "source": [
        "!git clone https://github.com/chengyangfu/pytorch-vgg-cifar10.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-vgg-cifar10'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Total 67 (delta 0), reused 0 (delta 0), pack-reused 67\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px8eH1d3ot9I",
        "outputId": "69e36deb-f247-4471-de53-9b4148d483e9"
      },
      "source": [
        "cd pytorch-vgg-cifar10/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch-vgg-cifar10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Ql-gk2-mow9P",
        "outputId": "226d3902-e69a-413e-8e40-900286db4295"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7bf340fa-b9f1-4be1-b5b5-e1ad881deb27\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7bf340fa-b9f1-4be1-b5b5-e1ad881deb27\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving smart_exchange_v2.py to smart_exchange_v2.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BDql4h0o0v9",
        "outputId": "2dd6b002-90e2-43bf-93f3-6863dd7efbb3"
      },
      "source": [
        "!wget http://www.cs.unc.edu/~cyfu/cifar10/model_best.pth.tar\n",
        "!python main.py --resume=./model_best.pth.tar -e\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 14:56:07--  http://www.cs.unc.edu/~cyfu/cifar10/model_best.pth.tar\n",
            "Resolving www.cs.unc.edu (www.cs.unc.edu)... 152.2.142.1\n",
            "Connecting to www.cs.unc.edu (www.cs.unc.edu)|152.2.142.1|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82223980 (78M) [application/x-tar]\n",
            "Saving to: ‘model_best.pth.tar’\n",
            "\n",
            "model_best.pth.tar  100%[===================>]  78.41M  48.3MB/s    in 1.6s    \n",
            "\n",
            "2020-12-20 14:56:09 (48.3 MB/s) - ‘model_best.pth.tar’ saved [82223980/82223980]\n",
            "\n",
            "=> loading checkpoint './model_best.pth.tar'\n",
            "=> loaded checkpoint 'True' (epoch 233)\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "170500096it [00:01, 95013431.63it/s]                   \n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "main.py:220: UserWarning: This overload of cuda is deprecated:\n",
            "\tcuda(torch.device device, bool async, *, torch.memory_format memory_format)\n",
            "Consider using one of the following signatures instead:\n",
            "\tcuda(torch.device device, bool non_blocking, *, torch.memory_format memory_format) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  input = input.cuda(async=True)\n",
            "Test: [0/79]\tTime 1.191 (1.191)\tLoss 0.2798 (0.2798)\tPrec@1 95.312 (95.312)\n",
            "Test: [20/79]\tTime 0.018 (0.077)\tLoss 0.4300 (0.4210)\tPrec@1 91.406 (92.448)\n",
            "Test: [40/79]\tTime 0.051 (0.052)\tLoss 0.3954 (0.4370)\tPrec@1 92.188 (92.264)\n",
            "Test: [60/79]\tTime 0.054 (0.044)\tLoss 0.4454 (0.4327)\tPrec@1 92.969 (92.367)\n",
            " * Prec@1 92.430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WBo5eVOpohw",
        "outputId": "110e40ef-5e92-4220-d29c-e96fe9a623fb"
      },
      "source": [
        "!python main.py ---eval -resume=./model_best.pth.tar -e"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 15, in <module>\n",
            "    import smart_exchange_v2 as sm_exchange\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 30\n",
            "    if max_val is None:\n",
            "                      ^\n",
            "IndentationError: unindent does not match any outer indentation level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VI8VYqYslW1",
        "outputId": "1edfbce4-3962-4bab-e92b-9fe575eb9eb1"
      },
      "source": [
        "!python main.py ---eval -resume=./model_best.pth.tar -e"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 15, in <module>\n",
            "    import smart_exchange_v2 as sm_exchange\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 30\n",
            "    if max_val is None:\n",
            "                      ^\n",
            "IndentationError: unindent does not match any outer indentation level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA4VtFgjsvm9",
        "outputId": "c9ef991f-24cf-44b2-bb73-5a658460e994"
      },
      "source": [
        "!python main.py ---eval -resume=./model_best.pth.tar -e\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 15, in <module>\n",
            "    import smart_exchange_v2 as sm_exchange\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 30\n",
            "    if max_val is None:\n",
            "                      ^\n",
            "IndentationError: unindent does not match any outer indentation level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDAXAbyFtFSo",
        "outputId": "53662324-65bf-455a-b479-1d476b6dc094"
      },
      "source": [
        "!python main.py ---eval -resume=./model_best.pth.tar -e"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 15, in <module>\n",
            "    import smart_exchange_v2 as sm_exchange\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 30\n",
            "    if max_val is None:\n",
            "                      ^\n",
            "IndentationError: unindent does not match any outer indentation level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvc9rJqJtqd1",
        "outputId": "a337cd1d-c783-471c-bfd3-9c471c862775"
      },
      "source": [
        "!python main.py -eval -resume=./model_best.pth.tar -e"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 15, in <module>\n",
            "    import smart_exchange_v2 as sm_exchange\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 30\n",
            "    if max_val is None:\n",
            "                      ^\n",
            "IndentationError: unindent does not match any outer indentation level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "nHZ9qmF-vuA1",
        "outputId": "c0913ed2-76b6-4255-d3c1-bb1d597a3fd5"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8d16c7d9-c780-419e-b10f-751bfaf6c95e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8d16c7d9-c780-419e-b10f-751bfaf6c95e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving smart_exchange_v2.py to smart_exchange_v2.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOwp3gFexUmX",
        "outputId": "d1a07fc5-36ab-47c0-dd8a-13b5f91535b4"
      },
      "source": [
        "!python main.py -eval -resume=./model_best.pth.tar -e"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: main.py [-h] [--arch ARCH] [-j N] [--epochs N] [--start-epoch N] [-b N]\n",
            "               [--lr LR] [--momentum M] [--weight-decay W] [--print-freq N]\n",
            "               [--resume PATH] [-e] [--pretrained] [--half] [--cpu]\n",
            "               [--save-dir SAVE_DIR]\n",
            "main.py: error: argument -e/--evaluate: ignored explicit argument 'val'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhVnAsdFxafV",
        "outputId": "146a7b11-4b86-4480-9215-900e987159f7"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint './model_best.pth.tar'\n",
            "=> loaded checkpoint 'True' (epoch 233)\n",
            "Files already downloaded and verified\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 306, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 131, in main\n",
            "    sm_exchange.smart_net(model,**opts)\n",
            "NameError: name 'opts' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA7RhfFcxiH3",
        "outputId": "fea68812-5a75-4671-c10d-fd14b6b846dd"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  File \"main.py\", line 311\n",
            "    main()\n",
            "    ^\n",
            "IndentationError: unexpected indent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCf__KqRx0e8",
        "outputId": "dfd6af05-53c7-44cb-81a9-63a0d3ae8298"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint './model_best.pth.tar'\n",
            "=> loaded checkpoint 'True' (epoch 233)\n",
            "Files already downloaded and verified\n",
            "decompose layer 1... Traceback (most recent call last):\n",
            "  File \"main.py\", line 311, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 131, in main\n",
            "    sm_exchange.smart_net(model,**opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 515, in smart_net\n",
            "    wrecon, layer_decomps = smart_decompose(w, **opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 471, in smart_decompose\n",
            "    opts['threshold_row'] = threshold_row and (kh == 3)\n",
            "NameError: name 'threshold_row' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy3YceS4yCqp",
        "outputId": "b7a8e929-b0b0-4159-c048-2cdbf4cfb50e"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint './model_best.pth.tar'\n",
            "=> loaded checkpoint 'True' (epoch 233)\n",
            "Files already downloaded and verified\n",
            "decompose layer 1... joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 433, in parfun_matrix_decompose\n",
            "    Wprecon, Ces, Bs = matrix_decompose(Wp, **opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 403, in matrix_decompose\n",
            "    Ce, B, _ = core_decompose(A[upper:lower,left:right], **opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 261, in core_decompose\n",
            "    if decompose_scale:\n",
            "NameError: name 'decompose_scale' is not defined\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 311, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 131, in main\n",
            "    sm_exchange.smart_net(model,**opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 515, in smart_net\n",
            "    wrecon, layer_decomps = smart_decompose(w, **opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 482, in smart_decompose\n",
            "    delayed(parfun_matrix_decompose)(i, W[i,:,:], **opts) for i in range(cout))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1054, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 933, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.6/concurrent/futures/_base.py\", line 432, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.6/concurrent/futures/_base.py\", line 384, in __get_result\n",
            "    raise self._exception\n",
            "NameError: name 'decompose_scale' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4mrb2bwzBDx",
        "outputId": "f86c282d-ff16-4350-fb00-f8131ac7dcb3"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 15, in <module>\n",
            "    import smart_exchange_v2 as sm_exchange\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 570\n",
            "    save_Ce=True)\n",
            "          ^\n",
            "SyntaxError: invalid syntax\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J8k6DClzk4q",
        "outputId": "433d6732-4d20-453d-8354-7a8ea015cee5"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint './model_best.pth.tar'\n",
            "=> loaded checkpoint 'True' (epoch 233)\n",
            "Files already downloaded and verified\n",
            "decompose layer 1... joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 433, in parfun_matrix_decompose\n",
            "    Wprecon, Ces, Bs = matrix_decompose(Wp, **opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 403, in matrix_decompose\n",
            "    Ce, B, _ = core_decompose(A[upper:lower,left:right], **opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 261, in core_decompose\n",
            "    if decompose_scale:\n",
            "NameError: name 'decompose_scale' is not defined\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 312, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 131, in main\n",
            "    sm_exchange.smart_net(model,**opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 515, in smart_net\n",
            "    wrecon, layer_decomps = smart_decompose(w, **opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 482, in smart_decompose\n",
            "    delayed(parfun_matrix_decompose)(i, W[i,:,:], **opts) for i in range(cout))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1054, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 933, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.6/concurrent/futures/_base.py\", line 432, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.6/concurrent/futures/_base.py\", line 384, in __get_result\n",
            "    raise self._exception\n",
            "NameError: name 'decompose_scale' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgB8rtGYzyDK",
        "outputId": "36ef1777-db87-40d7-b633-9e5024437af5"
      },
      "source": [
        "!pwd\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrkFAISf9-c6",
        "outputId": "357aa417-6cad-4aee-b9dd-2c06d77a8094"
      },
      "source": [
        "!git clone https://github.com/chengyangfu/pytorch-vgg-cifar10.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-vgg-cifar10'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Total 67 (delta 0), reused 0 (delta 0), pack-reused 67\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpkRticQ-tg5",
        "outputId": "0e382508-d5a6-4f41-db36-3317272f86c4"
      },
      "source": [
        "!wget http://www.cs.unc.edu/~cyfu/cifar10/model_best.pth.tar"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 16:28:41--  http://www.cs.unc.edu/~cyfu/cifar10/model_best.pth.tar\n",
            "Resolving www.cs.unc.edu (www.cs.unc.edu)... 152.2.142.1\n",
            "Connecting to www.cs.unc.edu (www.cs.unc.edu)|152.2.142.1|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82223980 (78M) [application/x-tar]\n",
            "Saving to: ‘model_best.pth.tar’\n",
            "\n",
            "model_best.pth.tar  100%[===================>]  78.41M  53.0MB/s    in 1.5s    \n",
            "\n",
            "2020-12-20 16:28:43 (53.0 MB/s) - ‘model_best.pth.tar’ saved [82223980/82223980]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbk2FAAs-0jO",
        "outputId": "868b1642-1021-4b4d-96b6-41bed622392c"
      },
      "source": [
        "cd pytorch-vgg-cifar10/\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch-vgg-cifar10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_ibulgf-4yP",
        "outputId": "c0d13c39-0290-4d74-d0bc-018d257a502a"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'main.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgy9VOqT_CXp",
        "outputId": "55b9cc26-c77b-4db6-bceb-b064952e9a36"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  File \"main.py\", line 131\n",
            "    smart_ex.smart_net(model,**opts)\n",
            "                                   ^\n",
            "TabError: inconsistent use of tabs and spaces in indentation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qmyx7CH_IuI",
        "outputId": "5e8c3374-4c6b-4a84-9db8-05ae27d8686a"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  File \"main.py\", line 132\n",
            "    validate(val_loader, model, criterion)\n",
            "                                         ^\n",
            "IndentationError: unindent does not match any outer indentation level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt4QxTlE_dY1",
        "outputId": "0d9636a6-ac54-4874-b889-cbb7d9c3566f"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  File \"main.py\", line 132\n",
            "    validate(val_loader, model, criterion)\n",
            "                                         ^\n",
            "IndentationError: unindent does not match any outer indentation level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMBD3Yh2_llZ",
        "outputId": "d064bb2b-d34e-4e86-efe9-f85577b79e45"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> no checkpoint found at './model_best.pth.tar'\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "170500096it [00:01, 100659720.66it/s]                  \n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "decompose layer 1... Traceback (most recent call last):\n",
            "  File \"main.py\", line 312, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 131, in main\n",
            "    Wdecomp = smart_ex.smart_net(model,**opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 515, in smart_net\n",
            "    wrecon, layer_decomps = smart_decompose(w, **opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 471, in smart_decompose\n",
            "    opts['threshold_row'] = threshold_row and (kh == 3)\n",
            "NameError: name 'threshold_row' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYkXpPZV_zxW",
        "outputId": "fa2e6ccc-d501-4235-ad29-99321769fed2"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> no checkpoint found at './model_best.pth.tar'\n",
            "Files already downloaded and verified\n",
            "decompose layer 1... joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 433, in parfun_matrix_decompose\n",
            "    Wprecon, Ces, Bs = matrix_decompose(Wp, **opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 403, in matrix_decompose\n",
            "    Ce, B, _ = core_decompose(A[upper:lower,left:right], **opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 261, in core_decompose\n",
            "    if decompose_scale:\n",
            "NameError: name 'decompose_scale' is not defined\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 312, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 131, in main\n",
            "    Wdecomp = smart_ex.smart_net(model,**opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 515, in smart_net\n",
            "    wrecon, layer_decomps = smart_decompose(w, **opts)\n",
            "  File \"/content/pytorch-vgg-cifar10/smart_exchange_v2.py\", line 482, in smart_decompose\n",
            "    delayed(parfun_matrix_decompose)(i, W[i,:,:], **opts) for i in range(cout))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1054, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 933, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.6/concurrent/futures/_base.py\", line 432, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.6/concurrent/futures/_base.py\", line 384, in __get_result\n",
            "    raise self._exception\n",
            "NameError: name 'decompose_scale' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu3hhJm8AGc5",
        "outputId": "aa917f09-e55b-42e4-8efa-67ba755e2f7a"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> no checkpoint found at './model_best.pth.tar'\n",
            "Files already downloaded and verified\n",
            "decompose layer 1... done\n",
            "decompose layer 2... done\n",
            "decompose layer 3... done\n",
            "decompose layer 4... done\n",
            "decompose layer 5... done\n",
            "decompose layer 6... done\n",
            "decompose layer 7... done\n",
            "decompose layer 8... done\n",
            "decompose layer 9... done\n",
            "decompose layer 10... done\n",
            "decompose layer 11... done\n",
            "decompose layer 12... done\n",
            "decompose layer 13... done\n",
            "decompose layer 14... done\n",
            "decompose layer 15... done\n",
            "decompose layer 16... done\n",
            "decompose layer 17... done\n",
            "decompose layer 18... done\n",
            "decompose layer 19... done\n",
            "Test: [0/79]\tTime 0.894 (0.894)\tLoss 2.3022 (2.3022)\tPrec@1 10.156 (10.156)\n",
            "Test: [20/79]\tTime 0.025 (0.065)\tLoss 2.3025 (2.3032)\tPrec@1 12.500 (9.524)\n",
            "Test: [40/79]\tTime 0.037 (0.048)\tLoss 2.3048 (2.3030)\tPrec@1 8.594 (9.966)\n",
            "Test: [60/79]\tTime 0.040 (0.042)\tLoss 2.3041 (2.3028)\tPrec@1 8.594 (10.015)\n",
            " * Prec@1 10.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F43TqKxPAom6",
        "outputId": "2e671140-71e6-406a-96bb-e70360e2c8a8"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> no checkpoint found at './model_best.pth.tar'\n",
            "Files already downloaded and verified\n",
            "decompose layer 1... done\n",
            "decompose layer 2... done\n",
            "decompose layer 3... done\n",
            "decompose layer 4... done\n",
            "decompose layer 5... done\n",
            "decompose layer 6... done\n",
            "decompose layer 7... done\n",
            "decompose layer 8... done\n",
            "decompose layer 9... done\n",
            "decompose layer 10... done\n",
            "decompose layer 11... done\n",
            "decompose layer 12... done\n",
            "decompose layer 13... done\n",
            "decompose layer 14... done\n",
            "decompose layer 15... done\n",
            "decompose layer 16... done\n",
            "decompose layer 17... done\n",
            "decompose layer 18... done\n",
            "decompose layer 19... done\n",
            "Test: [0/79]\tTime 0.683 (0.683)\tLoss 2.3030 (2.3030)\tPrec@1 10.156 (10.156)\n",
            "Test: [20/79]\tTime 0.019 (0.056)\tLoss 2.3028 (2.3025)\tPrec@1 12.500 (10.045)\n",
            "Test: [40/79]\tTime 0.020 (0.043)\tLoss 2.3029 (2.3031)\tPrec@1 11.719 (9.813)\n",
            "Test: [60/79]\tTime 0.016 (0.039)\tLoss 2.3006 (2.3032)\tPrec@1 14.062 (10.015)\n",
            " * Prec@1 10.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l0LibIwBnI4",
        "outputId": "7f34c62f-d1d5-4a52-9406-5c52afa0f696"
      },
      "source": [
        "!./run_sh"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ./run_sh: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFzps5qYDINa",
        "outputId": "a7f9640b-b63f-4ecf-93b6-abd42ffe21f0"
      },
      "source": [
        "!./run.sh"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python main.py  --arch=vgg11  --save-dir=save_vgg11 |& tee -a log_vgg11\n",
            "Files already downloaded and verified\n",
            "decompose layer 1... python main.py  --arch=vgg11_bn  --save-dir=save_vgg11_bn |& tee -a log_vgg11_bn\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPkIBXQxG5U9",
        "outputId": "e0a58617-03e9-470f-ee67-3200c7e15ede"
      },
      "source": [
        "!./run_sh"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ./run_sh: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "oXkmLjjYHQLr",
        "outputId": "e28fa4c7-2737-4013-b430-4b9fa48c3fe0"
      },
      "source": [
        "python main.py --arch=vgg11 --epochs=10 --resume=./model_best.pth.tar "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-9e199cf09541>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python main.py --arch=vgg11 --epochs=10 --resume=./model_best.pth.tar\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B_n_30DKXLk",
        "outputId": "06d74237-2e2a-42f9-b0cb-0f00025d4de7"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> no checkpoint found at './model_best.pth.tar'\n",
            "Files already downloaded and verified\n",
            "Test: [0/79]\tTime 0.594 (0.594)\tLoss 2.2989 (2.2989)\tPrec@1 14.844 (14.844)\n",
            "Test: [20/79]\tTime 0.014 (0.047)\tLoss 2.3001 (2.3026)\tPrec@1 11.719 (10.603)\n",
            "Test: [40/79]\tTime 0.038 (0.038)\tLoss 2.3044 (2.3035)\tPrec@1 10.156 (9.870)\n",
            "Test: [60/79]\tTime 0.014 (0.035)\tLoss 2.3022 (2.3032)\tPrec@1 8.594 (9.849)\n",
            " * Prec@1 10.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyAPPn52LBe8",
        "outputId": "358c885b-4fd9-47be-afed-15079b3fa8d4"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> no checkpoint found at './model_best.pth.tar'\n",
            "Files already downloaded and verified\n",
            "Test: [0/79]\tTime 0.683 (0.683)\tLoss 2.3027 (2.3027)\tPrec@1 7.812 (7.812)\n",
            "Test: [20/79]\tTime 0.015 (0.056)\tLoss 2.3029 (2.3029)\tPrec@1 13.281 (10.119)\n",
            "Test: [40/79]\tTime 0.018 (0.043)\tLoss 2.3049 (2.3029)\tPrec@1 9.375 (10.556)\n",
            "Test: [60/79]\tTime 0.019 (0.038)\tLoss 2.3047 (2.3030)\tPrec@1 9.375 (10.784)\n",
            " * Prec@1 10.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7X-l9GWLb0Z",
        "outputId": "9e3b9a02-2583-4826-e5de-e78a93677c2d"
      },
      "source": [
        "!wget http://www.cs.unc.edu/~cyfu/cifar10/model_best.pth.tar"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 17:24:58--  http://www.cs.unc.edu/~cyfu/cifar10/model_best.pth.tar\n",
            "Resolving www.cs.unc.edu (www.cs.unc.edu)... 152.2.142.1\n",
            "Connecting to www.cs.unc.edu (www.cs.unc.edu)|152.2.142.1|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82223980 (78M) [application/x-tar]\n",
            "Saving to: ‘model_best.pth.tar’\n",
            "\n",
            "model_best.pth.tar  100%[===================>]  78.41M   102MB/s    in 0.8s    \n",
            "\n",
            "2020-12-20 17:24:59 (102 MB/s) - ‘model_best.pth.tar’ saved [82223980/82223980]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duPsJH0jLs_9",
        "outputId": "09f26d62-cfb8-4f8b-a715-a4e6bccdeedf"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint './model_best.pth.tar'\n",
            "=> loaded checkpoint 'True' (epoch 233)\n",
            "Files already downloaded and verified\n",
            "Test: [0/79]\tTime 0.641 (0.641)\tLoss 0.2798 (0.2798)\tPrec@1 95.312 (95.312)\n",
            "Test: [20/79]\tTime 0.016 (0.054)\tLoss 0.4300 (0.4210)\tPrec@1 91.406 (92.448)\n",
            "Test: [40/79]\tTime 0.017 (0.043)\tLoss 0.3954 (0.4370)\tPrec@1 92.188 (92.264)\n",
            "Test: [60/79]\tTime 0.022 (0.038)\tLoss 0.4454 (0.4327)\tPrec@1 92.969 (92.367)\n",
            " * Prec@1 92.430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC9x7WwbLwm1",
        "outputId": "121fedd9-21d0-4d5b-f3be-b5418383aada"
      },
      "source": [
        "!python main.py --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint './model_best.pth.tar'\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 313, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 86, in main\n",
            "    model.load_state_dict(checkpoint['state_dict'])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 1052, in load_state_dict\n",
            "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
            "RuntimeError: Error(s) in loading state_dict for VGG:\n",
            "\tMissing key(s) in state_dict: \"features.module.3.weight\", \"features.module.3.bias\", \"features.module.6.weight\", \"features.module.6.bias\", \"features.module.8.weight\", \"features.module.8.bias\", \"features.module.11.weight\", \"features.module.11.bias\", \"features.module.13.weight\", \"features.module.13.bias\", \"features.module.18.weight\", \"features.module.18.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"features.module.21.weight\", \"features.module.21.bias\", \"features.module.23.weight\", \"features.module.23.bias\", \"features.module.25.weight\", \"features.module.25.bias\", \"features.module.28.weight\", \"features.module.28.bias\", \"features.module.30.weight\", \"features.module.30.bias\", \"features.module.32.weight\", \"features.module.32.bias\", \"features.module.34.weight\", \"features.module.34.bias\", \"features.module.2.weight\", \"features.module.2.bias\", \"features.module.5.weight\", \"features.module.5.bias\", \"features.module.7.weight\", \"features.module.7.bias\", \"features.module.10.weight\", \"features.module.10.bias\", \"features.module.12.weight\", \"features.module.12.bias\", \"features.module.14.weight\", \"features.module.14.bias\", \"features.module.19.weight\", \"features.module.19.bias\". \n",
            "\tsize mismatch for features.module.16.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "\tsize mismatch for features.module.16.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2RD0DhjL349",
        "outputId": "0bb5ddf5-0b2e-4557-81c2-005a047b19fd"
      },
      "source": [
        "!python main.py --arch=vgg11 --resume=./model_best.pth.tar -e"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint './model_best.pth.tar'\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 313, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 86, in main\n",
            "    model.load_state_dict(checkpoint['state_dict'])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 1052, in load_state_dict\n",
            "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
            "RuntimeError: Error(s) in loading state_dict for VGG:\n",
            "\tMissing key(s) in state_dict: \"features.module.3.weight\", \"features.module.3.bias\", \"features.module.6.weight\", \"features.module.6.bias\", \"features.module.8.weight\", \"features.module.8.bias\", \"features.module.11.weight\", \"features.module.11.bias\", \"features.module.13.weight\", \"features.module.13.bias\", \"features.module.18.weight\", \"features.module.18.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"features.module.21.weight\", \"features.module.21.bias\", \"features.module.23.weight\", \"features.module.23.bias\", \"features.module.25.weight\", \"features.module.25.bias\", \"features.module.28.weight\", \"features.module.28.bias\", \"features.module.30.weight\", \"features.module.30.bias\", \"features.module.32.weight\", \"features.module.32.bias\", \"features.module.34.weight\", \"features.module.34.bias\", \"features.module.2.weight\", \"features.module.2.bias\", \"features.module.5.weight\", \"features.module.5.bias\", \"features.module.7.weight\", \"features.module.7.bias\", \"features.module.10.weight\", \"features.module.10.bias\", \"features.module.12.weight\", \"features.module.12.bias\", \"features.module.14.weight\", \"features.module.14.bias\", \"features.module.19.weight\", \"features.module.19.bias\". \n",
            "\tsize mismatch for features.module.16.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "\tsize mismatch for features.module.16.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUYCIGObMUMo"
      },
      "source": [
        "!$model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WnP4FsqMZve",
        "outputId": "58a3f3f5-7bf2-47ff-87de-0d3dba113239"
      },
      "source": [
        "!model.args\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: model.args: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p0_RmvZMc_C",
        "outputId": "dcd34ab0-7b18-4cb8-9777-67ce71cd7ec1"
      },
      "source": [
        "!python main.py --pretrained --start--epochs=10 --resume=./model_best.pth.tar "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint './model_best.pth.tar'\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 313, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 86, in main\n",
            "    model.load_state_dict(checkpoint['state_dict'])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 1052, in load_state_dict\n",
            "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
            "RuntimeError: Error(s) in loading state_dict for VGG:\n",
            "\tMissing key(s) in state_dict: \"features.module.3.weight\", \"features.module.3.bias\", \"features.module.6.weight\", \"features.module.6.bias\", \"features.module.8.weight\", \"features.module.8.bias\", \"features.module.11.weight\", \"features.module.11.bias\", \"features.module.13.weight\", \"features.module.13.bias\", \"features.module.18.weight\", \"features.module.18.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"features.module.21.weight\", \"features.module.21.bias\", \"features.module.23.weight\", \"features.module.23.bias\", \"features.module.25.weight\", \"features.module.25.bias\", \"features.module.28.weight\", \"features.module.28.bias\", \"features.module.30.weight\", \"features.module.30.bias\", \"features.module.32.weight\", \"features.module.32.bias\", \"features.module.34.weight\", \"features.module.34.bias\", \"features.module.2.weight\", \"features.module.2.bias\", \"features.module.5.weight\", \"features.module.5.bias\", \"features.module.7.weight\", \"features.module.7.bias\", \"features.module.10.weight\", \"features.module.10.bias\", \"features.module.12.weight\", \"features.module.12.bias\", \"features.module.14.weight\", \"features.module.14.bias\", \"features.module.19.weight\", \"features.module.19.bias\". \n",
            "\tsize mismatch for features.module.16.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "\tsize mismatch for features.module.16.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCmUTYLbOOiu"
      },
      "source": [
        "!./run.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqiuE3HwSEd7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}